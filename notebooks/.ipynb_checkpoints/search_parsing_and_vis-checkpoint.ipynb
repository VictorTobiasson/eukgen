{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c66d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import altair as alt\n",
    "from Bio import SeqIO\n",
    "import multiprocessing\n",
    "\n",
    "#my HHsuite module in ~/scripts\n",
    "import parseHHsuite as HH\n",
    "\n",
    "#----- NOTEBOOK CONFIG ------\n",
    "\n",
    "#disable altair max rows\n",
    "alt.data_transformers.disable_max_rows()\n",
    "#get default altair style\n",
    "%run ~/scripts/altair_style_config_default.py\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "#enable output scrolling rather than wrapping\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "root = '/home/tobiassonva/data/eukgen/'\n",
    "%cd {root}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309853a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print mmeory usage of python objects\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "a = sorted([(x, sys.getsizeof(globals().get(x))/(1024**3)) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "print(*[size for size in a], sep='\\n')\n",
    "sum([size[1] for size in a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e65456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small helper for pkl parsing\n",
    "def load_pkl(pkl_file):\n",
    "    import parseHHsuite as HH\n",
    "    with open(pkl_file, 'rb') as infile:\n",
    "        item = pickle.load(infile)\n",
    "    return item\n",
    "\n",
    "def dump_pkl(item, pkl_file):\n",
    "    with open(pkl_file, 'wb') as outfile:\n",
    "        pickle.dump(item, outfile)\n",
    "    print(f'Pickled item as {pkl_file}')\n",
    "\n",
    "#pandas helper function to reset_index inplace\n",
    "def reindex(df, column):\n",
    "    df.sort_values(by=column, inplace=True)\n",
    "    df.set_index(keys=[column], drop=True,inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "#take a list of strings and return counts of words separated by spaces \n",
    "#ignores anything contained in regex blacklist expression\n",
    "def calculate_label_counts(labels, blacklist='(protein)'):\n",
    "    words = [label.split() for label in labels]\n",
    "    words = [item for sublist in words for item in sublist]\n",
    "    \n",
    "    #remove common phrases from filter\n",
    "    words = pd.Series(words)[~(pd.Series(words).str.contains(blacklist, regex=True))]\n",
    "\n",
    "    word_counts = words.value_counts()\n",
    "    \n",
    "    return word_counts\n",
    "\n",
    "\n",
    "\n",
    "#basic try to ammend the cropping of profile headers employed by hhsuite, capped at 138 or 142 chars??\n",
    "#requires searchDF from parse_HHsuite or equivalent Query, Target dataframe\n",
    "#requires global reference header mapping for both query and targets containing acc and header info as index\n",
    "\n",
    "def create_hhsuite_header_mapping(searchDF, global_header_mapping):\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    #append Target and Query columns \n",
    "    entries = pd.concat([searchDF.Query, searchDF.Target]).unique()\n",
    "\n",
    "    #iterate over entries and try to find a accession\n",
    "    for hit in entries:\n",
    "        #initial attempt by direct matching\n",
    "        try:\n",
    "            hit_acc = global_header_mapping.loc[hit].acc\n",
    "        \n",
    "        #for cropped entriestry to slice acc from first space separated element\n",
    "        #then refer to the global mapping for header\n",
    "        except KeyError:\n",
    "            print('cannot find hit for', hit)\n",
    "            print('trying via acc')\n",
    "            hit_acc = hit.split()[0]\n",
    "            new_header = global_header_mapping[global_header_mapping.acc == hit_acc].index[0]\n",
    "            #print(new_header)\n",
    "            #print('new acc is', hit_acc) \n",
    "        accs.append(hit_acc)\n",
    "\n",
    "    #format and return DF\n",
    "    hhsuite_header_mapping = pd.DataFrame({'acc': accs, 'header':entries})\n",
    "\n",
    "    hhsuite_header_mapping.sort_values(by='header', inplace=True)\n",
    "    hhsuite_header_mapping.set_index(keys=['header'], drop=True,inplace=True)\n",
    "    \n",
    "    return hhsuite_header_mapping\n",
    "\n",
    "\n",
    "#alignment \"viewer style\" plot for HHSuite alignments\n",
    "#takes input as pandas Series containing the 6 series of an HHSuite alignment\n",
    "#returns the processed dataframe and the altari chart object\n",
    "#\n",
    "#Query_sequence     RRRILGPMSSMMMAMAFLSTYPPEFIKRGLEGLRPDGRRPNELRPI...\n",
    "#Query_consensus    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~R~DGR~~delRpI...\n",
    "#Matches            |+..++.-.||||.+.--   +++-+  ..+++|+|||.+||+|||...\n",
    "#Target_consensus   ~~~~~~~~~~~~~~~~~~---~~~~~--~~~~~R~dGR~~deLRpv...\n",
    "#Target_sequence    LSHWLGASGSMMMMMTMQ---MPKLI--DENMMRPDGRAPDELRPV...\n",
    "#Confidence         455667677777765432   22333  249999999999999999...\n",
    "\n",
    "def plot_alignment(alignmentDF, query_name, target_name):\n",
    "\n",
    "    alignmentDF = pd.DataFrame({i:list(alignmentDF[i]) for i in alignmentDF.index})\n",
    "    alignmentDF['seqn'] = alignmentDF.index\n",
    "    alignmentDF['opacity'] = [np.tanh(int(i)/4) if i != ' ' else 0 for i in alignmentDF.Confidence]\n",
    "    alignmentDF_melt = alignmentDF.melt(id_vars=['seqn', 'opacity'], value_vars=alignmentDF.columns[:-1], var_name='series', value_name='token')\n",
    "\n",
    "\n",
    "\n",
    "    #style configuration\n",
    "    token_color_dict = {'-': 'white','~': 'white','|': 'white', '+': 'white','.': 'white',' ': 'white',\n",
    "                    '1': 'white', '2': 'white', '3': 'white', '4': 'white', '5': 'white', '6': 'white', '7': 'white', '8': 'white', '9': 'white',\n",
    "                    'R': '#6276ba', 'K': '#7297c1', 'H': '#7297c1', 'D': '#b25652', 'E': '#b25652', 'S': '#b5b65e', 'T': '#94ae57', 'N': '#72a551', 'Q': '#72a551', 'C': '#cca389', 'G': '#c4ced4', 'P': '#95b5c7', 'A': '#bfa764', 'V': '#b5b65e', 'I': '#94ae57', 'L': '#72a551', 'M': '#cca389', 'F': '#d8c7be', 'Y': '#c4ced4', 'W': '#6276ba',\n",
    "                    'r': '#c7cee6', 'k': '#b5c9df', 'h': '#b5c9df', 'd': '#e3c2c0', 'e': '#e3c2c0', 's': '#e6e6c6', 't': '#c8d6a8', 'n': '#bed7ae', 'q': '#bed7ae', 'c': '#ead6c9', 'g': '#eef1f3', 'p': '#d1e0e8', 'a': '#e0d6b5', 'v': '#e6e6c6', 'i': '#c8d6a8', 'l': '#bed7ae', 'm': '#dfc7b6', 'f': '#eee7e3', 'y': '#e0e6e8', 'w': '#b5bfde'}\n",
    "\n",
    "    seq_len = alignmentDF_melt.seqn.max()\n",
    "    series_number = len(alignmentDF.columns)\n",
    "    scale = 12\n",
    "\n",
    "    title = ['Query:    \\t'+query_name, 'Target:   \\t'+target_name]\n",
    "\n",
    "    token_names = list(token_color_dict.keys())\n",
    "    token_colors = list(token_color_dict.values())\n",
    "    sort_order = ['Confidence', 'Query_sequence', 'Query_consensus', 'Matches', 'Target_consensus', 'Target_sequence']\n",
    "\n",
    "    #base chart \n",
    "    base = alt.Chart(alignmentDF_melt, title=title).encode(\n",
    "        alt.X('seqn:O', axis=alt.Axis(title=None, values=list(range(0,seq_len,5)), grid=False)),\n",
    "        alt.Y('series:O', sort=sort_order, axis=alt.Axis(grid=False, title=None, labelFontSize=scale)),\n",
    "        alt.Opacity('opacity', legend=None),\n",
    "    ).properties(width=seq_len*scale*1.4, height=series_number*scale*1.4)\n",
    "\n",
    "    #residue labels\n",
    "    text = base.mark_text(color ='black', align='center', fontSize=scale).encode(\n",
    "        alt.Text('token')\n",
    "    )\n",
    "\n",
    "    #colored boxes\n",
    "    box = base.mark_rect().encode(\n",
    "        alt.Color('token', scale=alt.Scale(domain=token_names, range=token_colors),\n",
    "                 legend=alt.Legend(direction='horizontal', columns=4, orient='left', title=None, labelFontSize=scale,\n",
    "                                   values=['R', 'K', 'H', 'D', 'E', 'S', 'T', 'N', 'Q', 'C', 'G', 'P', 'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W']))\n",
    "    )\n",
    "\n",
    "    chart = alt.layer(box, text).configure_title(fontSize=scale*1.5)\n",
    "\n",
    "    return alignmentDF, chart\n",
    "\n",
    "\n",
    "#calculate cumulative sum and distribution for pd.Series\n",
    "#takes pd.Series as input and returns a parsed DF and altair chart object \n",
    "def plot_cumsum_counts(series, title='Chart', x_label='value', y_label='count', \n",
    "                       x_min=0, y_min=0, x_max=None, y_max=None,\n",
    "                       x_scale_type='log', y_scale_type='log', decimals=2):\n",
    "    \n",
    "    #format DF for data handling, filter 0 values for plot \n",
    "    #round to reduce float data display jaggedness\n",
    "    series = series[series!=0].round(decimals)\n",
    "    \n",
    "    #format distribution dataframe\n",
    "    countDF = pd.DataFrame(series.value_counts())\n",
    "    countDF.columns = ['amount']\n",
    "    countDF.sort_index(inplace=True)\n",
    "    countDF['cumsum'] = countDF['amount'].cumsum()\n",
    "    countDF['frac_cumsum'] = countDF['cumsum']/countDF['cumsum'].max()\n",
    "    countDF.reset_index(inplace=True)\n",
    "    \n",
    "    #rename columns for plotting\n",
    "    countDF.columns = [x_label,y_label,'cumsum','frac_cumsum']\n",
    "\n",
    "    #format axis domains\n",
    "    x_range = [x_min, series.max()]\n",
    "    y_range = [y_min, countDF[y_label].max()]\n",
    "    \n",
    "    if x_max:\n",
    "        x_range = [x_min, x_max]\n",
    "    \n",
    "    if y_max:\n",
    "        y_range = [y_min, y_max]\n",
    "        \n",
    "    #plot cumulative distribution\n",
    "    chart_cumsum = alt.Chart(countDF, title=title).mark_line(color=colorlib['twilight_shifted_r_perm'][2],\n",
    "                                              strokeWidth=3).encode(\n",
    "        x=alt.X(x_label, title=x_label, scale=alt.Scale(type=x_scale_type)),\n",
    "        y=alt.Y('frac_cumsum', title='Cumulative Fraction', scale=alt.Scale(domain=[0,1]), axis=alt.Axis(labelAlign='left')),\n",
    "        tooltip=alt.Tooltip([x_label, y_label, 'frac_cumsum'])\n",
    "    )\n",
    "    \n",
    "    #plot value distribution\n",
    "    chart_bar = alt.Chart(countDF).mark_area(interpolate='step-after', \n",
    "                                            fillOpacity=0.2, line=True).encode(\n",
    "        x=alt.X(x_label+':Q', scale=alt.Scale(domain=x_range, type=x_scale_type)),\n",
    "        y=alt.Y(y_label, scale=alt.Scale(domain=y_range, type=y_scale_type)),\n",
    "        tooltip=alt.Tooltip([x_label, y_label, 'frac_cumsum'])\n",
    "    )\n",
    "\n",
    "    #merge and configure\n",
    "    merge = alt.layer(chart_bar, chart_cumsum).resolve_scale(y='independent').interactive()\n",
    "\n",
    "    return countDF, merge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#parse HHSuite outfut fromm ffdata into pkl files \n",
    "def parse_and_write(file):\n",
    "    print(file)\n",
    "    new_data = HH.load_HHBlitsData(file)\n",
    "    new_data.write_pkl(file+'.pkl')\n",
    "    #new_data.write_data_tsv(file+'.tsv')\n",
    "\n",
    "\n",
    "def parse_filter_write(file):\n",
    "    thread = multiprocessing.current_process().pid\n",
    "    print(f'{thread} reading {file}\\n')\n",
    "    new_data = HH.load_HHBlitsData(file)\n",
    "    new_data.write_pkl(file+'.pkl')\n",
    "    print(f'{thread} parsing\\n')\n",
    "\n",
    "    for key, query in new_data.data.items():\n",
    "        query.add_self_hit()\n",
    "        query.filter_numeric(field='Pairwise_cov', min=20, replace=True, keep_self=True)\n",
    "        query.filter_numeric(field='Prob', min=50, replace=True, keep_self=True)\n",
    "    \n",
    "    print(f'{thread} writing\\n')\n",
    "    new_data.write_pkl(file+'.pkl_filtered')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c58105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parallel read and filter all data in files, save to pkl\n",
    "\n",
    "search_root='search/euk-prok/search/'\n",
    "files = [search_root+file for file in os.listdir(search_root) if file.endswith('ffdata')]\n",
    "\n",
    "with multiprocessing.Pool(processes=16) as pool:\n",
    "    pool.map(parse_filter_write, files)\n",
    "    \n",
    "\n",
    "    \n",
    "#open all parsed pkl files in folder and merge into one object\n",
    "\n",
    "all_data = HH.HHblitsData()\n",
    "search_root='search/euk-prok/pkl/'\n",
    "pkl_filtered_files = [file for file in os.listdir(search_root) if file.endswith('pkl')]\n",
    "\n",
    "for i, file in enumerate(pkl_filtered_files):\n",
    "    print(i,file)\n",
    "    new_data = HH.HHblitsData()\n",
    "    new_data.load_from_pkl(search_root+file)\n",
    "    all_data.add_entries(new_data.data)\n",
    "\n",
    "    \n",
    "#all_data.write_pkl(search_root+'merged_filtered_self-match.pkl')\n",
    "#all_data.write_data_tsv(search_root+'merged_filtered_self-match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data from /analysis/core_data\n",
    "\n",
    "#clustering data\n",
    "\n",
    "print('Loading clustering data')\n",
    "euk_clust = load_pkl(root+'analysis/core_data/euk72_filtered-prof-search-clust.pkl')['members']\n",
    "prok_clust = load_pkl(root+'analysis/core_data/prok2111_filtered-prof-search-clust.pkl')['members']\n",
    "\n",
    "reindex(euk_clust, 'cluster_acc')\n",
    "reindex(prok_clust, 'cluster_acc')\n",
    "\n",
    "# header mapping\n",
    "\n",
    "print('Loading header mapping')\n",
    "euk_header = load_pkl(root+'analysis/core_data/euk72_header_mapping.pkl')\n",
    "prok_header = load_pkl(root+'analysis/core_data/prok2111_header_mapping.pkl')\n",
    "\n",
    "reindex(euk_header, 'header')\n",
    "reindex(prok_header, 'header')\n",
    "\n",
    "#hhsuite profile header mapping as hhsuite crops header info\n",
    "hhsuite_header = load_pkl(root+'analysis/core_data/hhsuite_header_mapping.pkl')\n",
    "\n",
    "#cluster taxonomic filter info\n",
    "print('Loading taxonomy info')\n",
    "euk_tax = load_pkl('euk72/euk72_protein_taxonomy.pkl')\n",
    "\n",
    "#full prok tax\n",
    "#prok_tax = load_pkl('prok2111/prok2111_protein_taxonomy.pkl')\n",
    "\n",
    "#lighter parsed version\n",
    "prok_tax = load_pkl('analysis/core_data/prok2111_protein_taxonomy_trimmed.pkl')\n",
    "\n",
    "#search data\n",
    "print('Loading search data')\n",
    "#full searchDF\n",
    "#searchDF = load_pkl(root+'analysis/core_data/merged_filtered_cov20_self-match_tsv.pkl')\n",
    "\n",
    "#parsed acc viersion without alignment, self hits and indexed in query\n",
    "searchDF = load_pkl('analysis/core_data/merged_filtered_cov20_self-match_tsv_edited_no_aln.pkl')\n",
    "\n",
    "search_queries = load_pkl(root+'analysis/core_data/merged_filtered_cov20_self-match_tsv.query.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example quesries for testing\n",
    "euk_queries_test1 = ['OLP83888.1', 'SPQ97222.1', 'XP_009012109.1', 'XP_001461706.1',\n",
    "       'OLP92683.1', 'XP_002965802.1', 'XP_024530808.1', 'OLP86390.1',\n",
    "       'KAA0160735.1', 'XP_002681799.1', 'XP_002113075.1', 'OLQ13277.1',\n",
    "       'XP_001469768.1', 'XP_008902708.1', 'XP_002682078.1', 'XP_024309865.1',\n",
    "       'OLP87304.1', 'XP_004365904.1', 'XP_012899378.1', 'XP_032224311.1',\n",
    "       'XP_032223284.1', 'XP_001707828.1', 'XP_005536084.1', 'XP_018187362.1',\n",
    "       'XP_645838.1', 'PXF40497.1', 'XP_005847475.1', 'KAA0160637.1',\n",
    "       'XP_013754706.1', 'XP_008905306.1']\n",
    "\n",
    "euk_queries_test2 = ['CBN77353.1', 'CEL94470.1', 'CEL98020.1', 'CEM00912.1',\n",
    "       'CEM13793.1', 'CEO94447.1', 'CEP02189.1', 'CEP02404.1',\n",
    "       'EPZ31333.1', 'GBG32138.1', 'GBG34166.1', 'GBG34636.1',\n",
    "       'GBG88810.1', 'KAA0151157.1', 'KAA0167757.1', 'KAA6364588.1',\n",
    "       'KAA6383781.1', 'NP_001022034.1', 'NP_001105121.2',\n",
    "       'NP_001170744.1', 'NP_001189295.1', 'NP_001242666.1',\n",
    "       'NP_001259573.1', 'NP_001261837.1', 'NP_001294564.1',\n",
    "       'NP_001307934.1', 'NP_001328712.1', 'NP_012528.1', 'NP_050092.1',\n",
    "       'NP_051148.1', 'NP_189541.1', 'NP_197350.1', 'NP_498455.2',\n",
    "       'NP_505960.3', 'NP_588329.1', 'NP_595422.1', 'NP_609709.1',\n",
    "       'NP_611238.2', 'NP_649295.1', 'OAD00700.1', 'OAD03858.1',\n",
    "       'OAD05886.1', 'OAE33051.1', 'OLP78629.1', 'OLQ06972.1',\n",
    "       'OLQ08228.1', 'OLQ08510.1', 'OLQ11720.1', 'OLQ12045.1',\n",
    "       'OLQ14344.1']\n",
    "\n",
    "euk_queries_test3 = ['XP_008911403.1', 'XP_011408184.1', 'XP_002681038.1', 'XP_002673113.1',\n",
    "                     'OAD09041.1', 'XP_001634466.1', 'XP_005765180.1', 'XP_011407364.1', \n",
    "                     'XP_005789988.1', 'KAA6344160.1', 'KAA6409619.1', 'XP_002287408.1',\n",
    "                     'OAE21175.1', 'RKP17192.1', 'XP_013760427.1', 'KAA0163767.1',\n",
    "                     'XP_002119908.1', 'XP_009692086.1']\n",
    "\n",
    "#queries in superkingdoms with between 20, 50 mmebers hitting less than 20 prokaryotic profiles\n",
    "#and the representative seuqence is from a fish, insect or mammal\n",
    "euk_queries_test4 = ['NP_001002332.1', 'NP_001240313.1',\n",
    "       'NP_001259573.1', 'NP_001260847.1', \n",
    "       'NP_001278869.1', 'NP_001307724.1', 'NP_001307934.1', 'NP_001334755.1',\n",
    "       'NP_001356620.1', 'NP_115888.1', \n",
    "       'NP_610753.1', 'NP_611238.2', 'NP_956312.1',\n",
    "       'NP_998197.1', 'NP_998403.1', 'XP_005256905.1',  'XP_017206845.1', 'XP_021326060.1', 'XP_021336265.1']\n",
    "\n",
    "#queries in superkingdoms with between 20, 50 mmebers hitting less than 20 prokaryotic profiles\n",
    "#and there are between 200 and 2000 prokaryotic hits \n",
    "euk_queries_test5 = ['AGK83073.1', 'CBN73833.1', 'CBN79086.1', 'CEM35385.1', 'CEO94447.1', 'CEP00213.1', 'CEP03651.1', 'EPZ30938.1', 'EPZ31301.1', 'GBG60132.1', \n",
    "'GBG70565.1', 'GBG80562.1', 'GBG83744.1', 'KAA0165271.1', 'KAA0172078.1', 'KAA6408708.1', 'NP_001002332.1', 'NP_001259573.1', 'NP_001294564.1',\n",
    " 'NP_001307724.1', 'NP_001328712.1', 'NP_001334755.1', 'NP_001356620.1', 'NP_011081.1', 'NP_050092.1', 'NP_594946.1', 'NP_610753.1', 'NP_848958.1',\n",
    "  'NP_849074.1', 'NP_956312.1', 'NP_998197.1', 'OAD04802.1', 'OAD06369.1', 'OAE33370.1', 'OLP84660.1', 'OLQ06972.1', 'OLQ08228.1', 'OLQ14344.1',\n",
    "   'OSX69435.1', 'OSX71470.1', 'OSX72678.1', 'OSX75094.1', 'OSX77054.1', 'PTQ50428.1', 'PXF41822.1', 'PXF45288.1', 'RKP17849.1', 'RKP18091.1', \n",
    "   'RKP20265.1', 'RWR93989.1', 'RWR97906.1', 'RWR98344.1', 'SLM34047.1', 'SLM40311.1', 'SLM40671.1', 'SPQ96285.1', 'SPQ98172.1']\n",
    "\n",
    "\n",
    "print('Done')\n",
    "\n",
    "#calcualtion of profiles to be included in MSA evaluation\n",
    "euk_lca = load_pkl('analysis/core_data/euk72_filtered-prof-search-clust.lca.pkl')\n",
    "euk_lca_superkingdom = euk_lca[euk_lca.lca.isin(['superkingdom'])].index.unique().values\n",
    "\n",
    "searchDF_filtered = searchDF[(searchDF.index.isin(euk_lca_superkingdom)) &\n",
    "                            (searchDF.Pairwise_cov > 0.5) &\n",
    "                            (searchDF.Prob > 50)]\n",
    "\n",
    "\n",
    "queries_filtered = searchDF_filtered.index.unique().values\n",
    "\n",
    "\n",
    "#extended set for full miscrocosm evalution testing\n",
    "wider_set = searchDF_filtered[(euk_clust.index.value_counts().between(20,1000)) & \n",
    "                  (searchDF.index.value_counts().between(2,500))]\n",
    "wider_set_queries = wider_set.sample(1000).index.unique()[0:200].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b64214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_microcosm(queries, query_hits, query_clusters, target_clusters, root):    \n",
    "    root_query = root+query+'/'\n",
    "    os.mkdir(root_query)\n",
    "\n",
    "    print(f'Q:{query}')\n",
    "    query_members = query_clusters.loc[query, 'acc']\n",
    "    hits = query_hits.loc[query]\n",
    "    members = target_clusters.loc[hits]\n",
    "\n",
    "    #write quesry accessions to .acc\n",
    "    with open(root_query+f'{query}.acc', 'w') as outfile:\n",
    "        outfile.write(pd.DataFrame(query_members).to_csv(sep='\\t', header=None, index=None))\n",
    "\n",
    "    with open(root_query+f'{query}.targets', 'w') as outfile:\n",
    "        outfile.write(pd.DataFrame(members).to_csv(sep='\\t', header=None))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system('rm -r microcosm4/*')\n",
    "for query in wider_set_queries:\n",
    "    structure_microcosm(query, searchDF_filtered.Target, euk_clust, prok_clust, 'microcosm2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cefeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'CBJ26283.1'\n",
    "structure_microcosm(query, searchDF_filtered.Target, euk_clust, prok_clust, 'microcosm2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = searchDF_filtered[(euk_clust.index.value_counts().between(20,100)) & \n",
    "                  (searchDF.index.value_counts().between(2,30))]\n",
    "\n",
    "wider_set = searchDF_filtered[(euk_clust.index.value_counts().between(20,1000)) & \n",
    "                  (searchDF.index.value_counts().between(2,500))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wider_set.sample(1000).index.unique()[0:200].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74746e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = 0\n",
    "\n",
    "for n, i in enumerate(searchDF_filtered.index.unique()):\n",
    "    hits = searchDF_filtered.loc[[i],'Target'].values\n",
    "    counts += prok_clust.loc[hits].shape[0]\n",
    "    print(n, round(counts/(n+1),1), counts, i, sep='\\t')\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'OAE21175.1'\n",
    "query_clusters = euk_clust\n",
    "query_hits = searchDF_filtered.Target\n",
    "target_clusters = prok_clust\n",
    "\n",
    "query_members = query_clusters.loc[query, 'acc']\n",
    "hits = query_hits.loc[query]\n",
    "members = target_clusters.loc[hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_clusters.loc[query, 'acc'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_file = 'microcosm2/KAA0163767.1/KAA0163767.1.acc'\n",
    "with open(cluster_file, 'r') as infile:\n",
    "    clusters = {}\n",
    "\n",
    "    for l in infile.readlines():\n",
    "        cluster_acc, acc = l.strip().split('\\t')\n",
    "\n",
    "        if cluster_acc not in clusters.keys():\n",
    "            clusters[cluster_acc] = [acc]\n",
    "\n",
    "        else:\n",
    "            clusters[cluster_acc].append(acc)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a series of query accessions, retreive all proteins from prokaryotic hits and return their phylogenetic distribution count\n",
    "#designed for multiprocess Pool and checkpointing to .pkl files\n",
    "#not very portable \n",
    "\n",
    "def get_hit_tax_dist(queries):\n",
    "    stime = time.time()\n",
    "    querynr = len(queries)\n",
    "    \n",
    "    thread = multiprocessing.current_process().pid\n",
    "    print(f'{thread}: started\\n')\n",
    "    \n",
    "    print(f'{thread}: processing {querynr} queries\\n')\n",
    "    \n",
    "    #load data from files \n",
    "    print(f'{thread}: loading search\\n')\n",
    "    searchDF = load_pkl(root+'analysis/core_data/merged_filtered_cov20_self-match_tsv_edited_no_aln.pkl')\n",
    "    \n",
    "    print(f'{thread}: loading clust\\n')\n",
    "    prok_clust = load_pkl(root+'analysis/core_data/prok2111_filtered-prof-search-clust.pkl')['members']\n",
    "    reindex(prok_clust, 'cluster_acc')\n",
    "\n",
    "    print(f'{thread}: loading tax\\n')\n",
    "    prok_tax = load_pkl('analysis/core_data/prok2111_protein_taxonomy_trimmed.pkl')\n",
    "\n",
    "    #process only the given slice\n",
    "    searchDF = searchDF[(searchDF.Query.isin(queries)) &\n",
    "                         (searchDF.Query != searchDF.Target) &\n",
    "                         (searchDF.Pairwise_cov > 0.5)]\n",
    "\n",
    "    #set index for faster iterating over queries\n",
    "    searchDF.sort_values(by='Query', inplace=True)\n",
    "    searchDF.set_index(keys=['Query'], drop=True, inplace=True)\n",
    "\n",
    "    #iterate and pool taxa distributions\n",
    "    taxa = {}\n",
    "    n = 0\n",
    "    printn = 50\n",
    "    checkn = 1000\n",
    "\n",
    "    for query in queries:\n",
    "        \n",
    "        if n%printn == 0:\n",
    "            print(f'{thread}: calculating {query} \\t{n}|{querynr} \\tT+{round(time.time()-stime)} seconds\\n')\n",
    "        \n",
    "        #find all target profile hits\n",
    "        profiles = pd.Series(searchDF.loc[query, 'Target'])\n",
    "\n",
    "        #find all proteins in target profile hits\n",
    "        proteins = pd.Series(prok_clust.loc[profiles,'acc'])\n",
    "\n",
    "        #find all taxonomic information from proteins in taget profile hits\n",
    "        query_taxa = prok_tax.loc[proteins, 'class'].value_counts()\n",
    "\n",
    "        #add to dict\n",
    "        taxa[query] = query_taxa\n",
    "        \n",
    "        #itermediate save\n",
    "        if n != 0 and n%checkn == 0:\n",
    "            print(f'{thread}: saved checkpoint {n/checkn}')\n",
    "            dump_pkl(taxa, f'analysis/core_data/tax/{thread}_checkpoint_{int(n/checkn)}_tax.pkl')\n",
    "            taxa = {}\n",
    "            \n",
    "        n+=1\n",
    "        \n",
    "    dump_pkl(taxa, f'analysis/core_data/tax/{thread}_tax.pkl')\n",
    "    return taxa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#launch parallel execution\n",
    "queries = searchDF[(searchDF.Query != searchDF.Target)\n",
    "                    & (searchDF.Pairwise_cov > 0.5)].Query.unique()\n",
    "\n",
    "splits = np.array_split(queries, 16)\n",
    "with multiprocessing.Pool(processes=16) as pool:\n",
    "    pool.map(get_hit_tax_dist, splits)\n",
    "    \n",
    "    \n",
    "#load data from savepoints into one dictionary\n",
    "tax_data = {}\n",
    "for file in os.listdir('analysis/core_data/tax/'):\n",
    "    print('analysis/core_data/tax/'+file)\n",
    "    data = load_pkl('analysis/core_data/tax/'+file)\n",
    "    tax_data = tax_data.copy()\n",
    "    tax_data.update(data)\n",
    "    \n",
    "#merge dict series into one dataframe\n",
    "query_tax = pd.DataFrame()\n",
    "for query, data in tax_data.items():\n",
    "    print(query)\n",
    "\n",
    "    data.name = query\n",
    "    \n",
    "    temp_tax = pd.DataFrame(data).transpose()\n",
    "    query_tax = pd.concat([query_tax, temp_tax])\n",
    "\n",
    "#save processed dataframe\n",
    "dump_pkl(query_tax, 'analysis/core_data/hit_distribution_cov50.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#calculate query statistics tables\n",
    "#load raw hit counts\n",
    "query_tax = load_pkl('analysis/core_data/hit_distribution_cov50.pkl')\n",
    "\n",
    "#normalize to relative total hits\n",
    "query_tax_rel = query_tax.div(query_tax.sum(axis=1), axis=0)\n",
    "#calculate percentile ranks for relative observations skipping 0 observations\n",
    "query_tax_rel_percentile = query_tax_rel.apply(lambda df: df[df!=0].rank(method='max', pct=True), axis=0).fillna(0)\n",
    "\n",
    "#multiply by individual hits to get weights\n",
    "query_tax_weight = pd.DataFrame(query_tax.values*query_tax_rel.values, columns=query_tax.columns, index=query_tax.index)\n",
    "#calculate percentile rank of observation of weight\n",
    "query_tax_weight_percentile = query_tax_weight.apply(lambda df: df.rank(method='max', pct=True), axis=0)\n",
    "\n",
    "\n",
    "#write proteins from query clusters which have top 10% relative hits in \n",
    "#respective taxon to file\n",
    "\n",
    "prominent_taxon_proteins = {}\n",
    "for taxon in query_tax.columns:\n",
    "    prominent_queries = query_tax_rel_percentile[(query_tax_rel_percentile[taxon].between(0.85, 0.90))].index\n",
    "    prominent_proteins = euk_clust.loc[prominent_queries, 'acc'].values\n",
    "\n",
    "    homo_tax = euk_tax[euk_tax['class'] == 'Mammalia']\n",
    "    prominent_homo_proteins = homo_tax[homo_tax.index.isin(prominent_proteins)].index\n",
    "    outdata = euk_header[euk_header.acc.isin(prominent_homo_proteins)]\n",
    "    print(taxon, outdata.shape[0])\n",
    "    outdata.reset_index(inplace=True)\n",
    "    \n",
    "    outdata['header'].to_csv(f'analysis/core_data/significant/{taxon.replace(\" \", \"_\")}.tsv', sep='\\t', index=None, header=None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fa6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#describe search results\n",
    "\n",
    "print('Load data')\n",
    "#load parse_HHSuite data from pkl \n",
    "search_data = HH.HHblitsData()\n",
    "search_data.load_from_pkl(root+'search/euk-prok/merged_filtered_cov20_self-match.pkl')\n",
    "\n",
    "#search block csv\n",
    "search_csv = pd.read_csv(root+'search/euk-prok/merged_filtered_cov20_self-match.csv', sep='\\t')\n",
    "#query block csv\n",
    "search_queries_csv = pd.read_csv(root+'search/euk-prok/merged_filtered_cov20_self-match.queries.csv', sep='\\t', index_col='Query')\n",
    "\n",
    "#remove self hits\n",
    "search_nonself_csv = search_csv[(search_csv.Query != search_csv.Target)]\n",
    "\n",
    "#total hits\n",
    "print(f'Total hits = {search_nonself_csv .shape[0]}\\n')\n",
    "\n",
    "#identities\n",
    "probs = search_nonself_csv.Prob.describe()\n",
    "print('Probability breakdown\\n', probs,'\\n')\n",
    "\n",
    "#probabilities\n",
    "ident = search_nonself_csv.Identities.describe()\n",
    "print('Identity breakdown\\n', ident,'\\n')\n",
    "\n",
    "\n",
    "#calculate number of hits per query and number of queries per hit\n",
    "print('calculating hit statistics\\n')\n",
    "hits = []\n",
    "for query in search_data.query_names[0:100000]:\n",
    "    query_data = pd.DataFrame(search_data.data[query].hit_dict)\n",
    "    hits.append(query_data[query_data.Target != query].shape[0])\n",
    "    \n",
    "inverse_hits = search_nonself_csv.Target.value_counts()\n",
    "\n",
    "print('Most frequent inverse hits\\n')\n",
    "print(inverse_hits[0:20], '\\n')\n",
    "\n",
    "print('most common words among inverse hits\\n')\n",
    "print(calculate_label_counts(inverse_hits[inverse_hits>100].index)[0:20], '\\n')\n",
    "\n",
    "#plot hit distributions\n",
    "plot_cumsum_counts(pd.Series(inverse_hits.values)) &  plot_cumsum_counts(pd.Series(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8465d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distribution of probabilities against identities\n",
    "\n",
    "subset = search_data[search_data.Query != search_data.Target].sample(100000)\n",
    "\n",
    "chart = alt.Chart(subset).mark_rect().encode(\n",
    "    x=alt.X('Prob:Q', bin=alt.Bin(extent=[0,100], step=1), axis=alt.Axis(grid=False)),\n",
    "    y=alt.Y('Identities:Q', bin=alt.Bin(extent=[0,100], step=1), axis=alt.Axis(grid=False)),\n",
    "    color=alt.Color('count()', scale=alt.Scale(scheme='bluepurple', domain=[-1,200]))\n",
    "\n",
    ").properties(width=800, height=450)\n",
    "\n",
    "\n",
    "#precomputed histogram for faster render\n",
    "#doesn't work properly\n",
    "\n",
    "xvalue='Prob'\n",
    "yvalue='Similarity'\n",
    "\n",
    "xbins = 100\n",
    "ybins = 100\n",
    "xrange = [subset[xvalue].min(), subset[xvalue].max()]\n",
    "yrange = [subset[yvalue].min(), subset[yvalue].max()]\n",
    "\n",
    "hist_data = np.histogram2d(subset[xvalue], subset[yvalue], \n",
    "                           bins=(np.linspace(xrange[0], xrange[1], xbins).round(2), \n",
    "                                 np.linspace(yrange[0], yrange[1], ybins).round(2)), density=True)\n",
    "x = []\n",
    "y = []\n",
    "v = []\n",
    "for i, m in enumerate(hist_data[1][:-1]):\n",
    "    for j, n in enumerate(hist_data[2][:-1]):\n",
    "        x.append(m)\n",
    "        y.append(n)\n",
    "        v.append(hist_data[0][i][j])\n",
    "        \n",
    "hist_data_plot = pd.DataFrame({'xbins': x, 'ybins': y, 'density': v})\n",
    "\n",
    "\n",
    "alt.Chart(hist_data_plot).mark_rect().encode(\n",
    "    x=alt.X('xbins:O', axis=alt.Axis(grid=False)),\n",
    "    y=alt.Y('ybins:O', axis=alt.Axis(grid=False)),\n",
    "    color = alt.Color('density',  scale=alt.Scale(scheme='bluepurple', domain=[min(v)*5, max(v)/10]))\n",
    ").properties(width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78364703",
   "metadata": {},
   "source": [
    "------ REFORMATTING FOR CLUSTERING --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e890c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirty check for label consistency of queries and blasttab formatting for mmseqs\n",
    "\n",
    "root = 'clust/euk72-profiles/profile-profile-hhsearch/'\n",
    "#header = ['Query','Target','Prob','E-value','P-value','Score','SS','Cols','Identities','Similarity','Sum_probs','Query-HMM-start','Query-HMM-end','Template-HMM-start','Template-HMM-end','Template_columns','Template_Neff']\n",
    "data = pd.read_csv(root+'merged_data_filtered_c80.tsv', sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = '/data/tobiassonva/data/eukgen/euk72/euk72.lookup'\n",
    "lookup = pd.read_csv(lookup, sep='\\t', header=None, index_col=1, names=['name', 'index', 'none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9616c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the labels to get accessions\n",
    "parse_query = [entry.split()[0] for entry in data.Query]\n",
    "parse_target = [entry.split()[0] for entry in data.Target]\n",
    "\n",
    "\n",
    "#find label discrepancies\n",
    "queries = parse_query\n",
    "entries = lookup.index\n",
    "\n",
    "clusters = '/data/tobiassonva/data/eukgen/clust/euk72-profiles/euk72_filtered-casc-clust-6-merged.tsv'\n",
    "clusters = pd.read_csv(clusters, sep ='\\t', header=None, names=['clust', 'mem'])['clust']\n",
    "\n",
    "a = set(queries).difference(set(clusters))\n",
    "b = set(clusters).difference(set(queries))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inconsistent labels from mmseqs internal parsing\n",
    "query = pd.Series(parse_query)\n",
    "\n",
    "query.replace('pir||A44923', 'A44923',inplace=True)\n",
    "query.replace('prf||1111187A', '1111187A', inplace=True)\n",
    "query.replace('prf||1111187C', '1111187C', inplace=True)\n",
    "\n",
    "target = pd.Series(parse_target)\n",
    "\n",
    "target.replace('pir||A44923', 'A44923',inplace=True)\n",
    "target.replace('prf||1111187A', '1111187A', inplace=True)\n",
    "target.replace('prf||1111187C', '1111187C', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2e35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_index = [lookup.loc[entry, 'name'] for entry in query]\n",
    "target_index = [lookup.loc[entry, 'name'] for entry in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa99569",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.Series(parse_query)\n",
    "query_index = [lookup.loc[entry, 'name'] for entry in query]\n",
    "print('target')\n",
    "target = pd.Series(parse_target)\n",
    "target_index = [lookup.loc[entry, 'name'] for entry in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Query = query_index\n",
    "data.Target = target_index\n",
    "data_queries = data.Query.unique()\n",
    "data_filtered = data[data.Target.isin(data_queries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format blasttab format mode 8 for mmseqs tsv2result\n",
    "blasttab_m8 = pd.DataFrame({'Query': data_filtered.Query, 'Target':data_filtered.Target})\n",
    "\n",
    "add_columns = ['Identities', 'Template_columns',  'Query-HMM-start','Query-HMM-end','Template-HMM-start','Template-HMM-end','E-value', 'Score']\n",
    "order = ['Query', 'Target', 'Identities', 'Template_columns', 'Mismatch', 'Gap_open', 'Query-HMM-start','Query-HMM-end','Template-HMM-start','Template-HMM-end','E-value', 'Score']\n",
    "\n",
    "\n",
    "blasttab_m8[add_columns] = data_filtered[add_columns]\n",
    "blasttab_m8['Mismatch'] = [0 for _ in blasttab_m8.index]\n",
    "blasttab_m8['Gap_open'] = [0 for _ in blasttab_m8.index]\n",
    "\n",
    "blasttab_m8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "blasttab_m8.to_csv(root+'merged_data_filtered_c80.tsv.blasttab', sep = '\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4031941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prob</th>\n",
       "      <th>E-value</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Score</th>\n",
       "      <th>SS</th>\n",
       "      <th>Cols</th>\n",
       "      <th>Identities</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>...</th>\n",
       "      <th>Template-HMM-end</th>\n",
       "      <th>Template_columns</th>\n",
       "      <th>Template_Neff</th>\n",
       "      <th>Pairwise_cov</th>\n",
       "      <th>Query_sequence</th>\n",
       "      <th>Query_consensus</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Target_consensus</th>\n",
       "      <th>Target_sequence</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBJ25674.1 hypothetical protein Esi_0008_0083 ...</td>\n",
       "      <td>CBJ25674.1 hypothetical protein Esi_0008_0083 ...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4493.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>100</td>\n",
       "      <td>1.460</td>\n",
       "      <td>...</td>\n",
       "      <td>1172</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERESWAEVQLAASVEVVALSFELAVQIFAETILVEAKGCQGSTQL...</td>\n",
       "      <td>|||++|+++||.++++|++.|||.|+|||+++|+.++|+||+++|+...</td>\n",
       "      <td>mereswaevqlaasvevvalsfelavqifaetilveakgcqgstql...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8999999999999999999999999999999999999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBJ25674.1 hypothetical protein Esi_0008_0083 ...</td>\n",
       "      <td>GBG24300.1</td>\n",
       "      <td>98.3</td>\n",
       "      <td>2.300000e-10</td>\n",
       "      <td>1.400000e-14</td>\n",
       "      <td>128.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455</td>\n",
       "      <td>23</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>672</td>\n",
       "      <td>1062</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.412116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WAEVQLAASVEVVALSFELAVQIFAETILVEAKGCQGSTQLILERV...</td>\n",
       "      <td>|++||||++|+|+|+++|+|+.+|||+|++++++++|+|+|++++|...</td>\n",
       "      <td>~~~L~~r~e~~v~g~~~e~a~~~Fan~l~~d~~~~~~~k~h~~l~i...</td>\n",
       "      <td>PTFLEFRVECFVSGPSIEKAFDIFANFLREDLQEINNSKDHILLGI...</td>\n",
       "      <td>8999999999999999999999999999999999999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3362.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>100</td>\n",
       "      <td>1.168</td>\n",
       "      <td>...</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MQSGPPPPSLFAARLVSALEHRAETAEQIAGERAKQVGELEGRVER...</td>\n",
       "      <td>|||||||||+|++|||+.|+||.+++++|+|+|+|+||+|++|+++...</td>\n",
       "      <td>mqsgppppslfaarlvsalehraetaeqiagerakqvgelegrver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8999999999999999999999999999999999999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.400000e-69</td>\n",
       "      <td>3.100000e-73</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>837</td>\n",
       "      <td>51</td>\n",
       "      <td>0.631</td>\n",
       "      <td>...</td>\n",
       "      <td>1070</td>\n",
       "      <td>1218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.759442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAARLVSALEHRAETAEQIAGERA-----------KQVGELEGRVE...</td>\n",
       "      <td>-++|||.+|++|++++++++.+|+           |+|.+|++|.+...</td>\n",
       "      <td>esarlvadleqrvrgaeslaaeraqqsaaskeaaakkiaeleqrae...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>468999999999999999999997           89999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>CBJ26231.1 conserved unknown protein [Ectocarp...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.300000e-68</td>\n",
       "      <td>9.800000e-73</td>\n",
       "      <td>571.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>845</td>\n",
       "      <td>50</td>\n",
       "      <td>0.601</td>\n",
       "      <td>...</td>\n",
       "      <td>966</td>\n",
       "      <td>1218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESARLVADLEQRVRGAESLAAERAQQSAASKEAAAKKIAELEQRAE...</td>\n",
       "      <td>.++|||+.|+||.+++++|+           |.++|++++|+++++...</td>\n",
       "      <td>faarlvsalehraetaeqia-----------gerakqvgelegrve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36899999999999999999           999999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818376</th>\n",
       "      <td>CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]</td>\n",
       "      <td>XP_005781423.1 hypothetical protein EMIHUDRAFT...</td>\n",
       "      <td>83.2</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>8.700000e-06</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>92</td>\n",
       "      <td>2.236</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPPPPPPPPPLPP   23 (89)pppppppppplpp   23 (89)</td>\n",
       "      <td>|||||||||||.|</td>\n",
       "      <td>pppppppppplqp  154 (227)</td>\n",
       "      <td>PPPPPPPPPPLQP  154 (227)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818377</th>\n",
       "      <td>CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]</td>\n",
       "      <td>XP_002295265.1 predicted protein [Thalassiosir...</td>\n",
       "      <td>83.1</td>\n",
       "      <td>2.100000e-01</td>\n",
       "      <td>8.900000e-06</td>\n",
       "      <td>40.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2.407</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPPPPPPLPP   23 (89)ppppppplpp   23 (89)</td>\n",
       "      <td>||||||||||</td>\n",
       "      <td>ppppppplpp   41 (494)</td>\n",
       "      <td>PPPPPPPLPP   41 (494)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818378</th>\n",
       "      <td>CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]</td>\n",
       "      <td>XP_009052733.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.900000e-01</td>\n",
       "      <td>9.000000e-06</td>\n",
       "      <td>44.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>0.732</td>\n",
       "      <td>...</td>\n",
       "      <td>1061</td>\n",
       "      <td>1430</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.030070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLRQTPPPPPPPPPPLPPVKPQGVTFRHSDDTWYSENEDDLLD   ...</td>\n",
       "      <td>|-..+||+||+|+|| ||..+-..--...++.||.+---|..+</td>\n",
       "      <td>~ptPtPP~~PtP~Pp-PptplP~fitQFkg~~Wf~~~fpd~~~ 10...</td>\n",
       "      <td>PPTPTPPRPPTPPPP-PPTPLPEFITQFKGSEWFEKFFPDAQP 10...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818379</th>\n",
       "      <td>CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]</td>\n",
       "      <td>XP_005766951.1 hypothetical protein EMIHUDRAFT...</td>\n",
       "      <td>82.7</td>\n",
       "      <td>2.200000e-01</td>\n",
       "      <td>9.500000e-06</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>1.791</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QTPPPPPPPPPPLPPVKP   26 (89)qtpppppppppplppvkp...</td>\n",
       "      <td>..||||||||||.||..|</td>\n",
       "      <td>epppppppppppqppqpp   90 (185)</td>\n",
       "      <td>EPPPPPPPPPPPQPPQPP   90 (185)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818380</th>\n",
       "      <td>CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]</td>\n",
       "      <td>OSX74078.1 hypothetical protein BU14_0311s0018...</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.300000e-01</td>\n",
       "      <td>9.800000e-06</td>\n",
       "      <td>37.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>1.607</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LRQTPPPPPPPPPPLPPVKP   26 (89)lrqtpppppppppplp...</td>\n",
       "      <td>+...||||||||||.||..|</td>\n",
       "      <td>mpppppppppppppppppsp   20 (253)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1818381 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Query  \\\n",
       "0        CBJ25674.1 hypothetical protein Esi_0008_0083 ...   \n",
       "1        CBJ25674.1 hypothetical protein Esi_0008_0083 ...   \n",
       "2        CBJ26231.1 conserved unknown protein [Ectocarp...   \n",
       "3        CBJ26231.1 conserved unknown protein [Ectocarp...   \n",
       "4        CBJ26231.1 conserved unknown protein [Ectocarp...   \n",
       "...                                                    ...   \n",
       "1818376       CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]   \n",
       "1818377       CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]   \n",
       "1818378       CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]   \n",
       "1818379       CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]   \n",
       "1818380       CBN80365.1 EsV-1-61 [Ectocarpus siliculosus]   \n",
       "\n",
       "                                                    Target   Prob  \\\n",
       "0        CBJ25674.1 hypothetical protein Esi_0008_0083 ...  100.0   \n",
       "1                                               GBG24300.1   98.3   \n",
       "2        CBJ26231.1 conserved unknown protein [Ectocarp...  100.0   \n",
       "3        CBJ26231.1 conserved unknown protein [Ectocarp...  100.0   \n",
       "4        CBJ26231.1 conserved unknown protein [Ectocarp...  100.0   \n",
       "...                                                    ...    ...   \n",
       "1818376  XP_005781423.1 hypothetical protein EMIHUDRAFT...   83.2   \n",
       "1818377  XP_002295265.1 predicted protein [Thalassiosir...   83.1   \n",
       "1818378                                     XP_009052733.1   83.0   \n",
       "1818379  XP_005766951.1 hypothetical protein EMIHUDRAFT...   82.7   \n",
       "1818380  OSX74078.1 hypothetical protein BU14_0311s0018...   82.5   \n",
       "\n",
       "              E-value       P-value   Score   SS  Cols  Identities  \\\n",
       "0        0.000000e+00  0.000000e+00  4493.3  0.0  1172         100   \n",
       "1        2.300000e-10  1.400000e-14   128.3  0.0   455          23   \n",
       "2        0.000000e+00  0.000000e+00  3362.8  0.0  1218         100   \n",
       "3        7.400000e-69  3.100000e-73   575.0  0.0   837          51   \n",
       "4        2.300000e-68  9.800000e-73   571.2  0.0   845          50   \n",
       "...               ...           ...     ...  ...   ...         ...   \n",
       "1818376  2.000000e-01  8.700000e-06    37.2  0.0    13          92   \n",
       "1818377  2.100000e-01  8.900000e-06    40.2  0.0    10         100   \n",
       "1818378  1.900000e-01  9.000000e-06    44.6  0.0    42          33   \n",
       "1818379  2.200000e-01  9.500000e-06    36.1  0.0    18          72   \n",
       "1818380  2.300000e-01  9.800000e-06    37.4  0.0    20          65   \n",
       "\n",
       "         Similarity  ...  Template-HMM-end  Template_columns  Template_Neff  \\\n",
       "0             1.460  ...              1172              1172            1.0   \n",
       "1             0.300  ...               672              1062            4.3   \n",
       "2             1.168  ...              1218              1218            1.0   \n",
       "3             0.631  ...              1070              1218            1.0   \n",
       "4             0.601  ...               966              1218            1.0   \n",
       "...             ...  ...               ...               ...            ...   \n",
       "1818376       2.236  ...               154               227            1.0   \n",
       "1818377       2.407  ...                41               494            1.0   \n",
       "1818378       0.732  ...              1061              1430            2.2   \n",
       "1818379       1.791  ...                90               185            1.0   \n",
       "1818380       1.607  ...                20               253            1.0   \n",
       "\n",
       "         Pairwise_cov  Query_sequence  \\\n",
       "0            1.000000             NaN   \n",
       "1            0.412116             NaN   \n",
       "2            1.000000             NaN   \n",
       "3            0.759442             NaN   \n",
       "4            0.764368             NaN   \n",
       "...               ...             ...   \n",
       "1818376      0.057269             NaN   \n",
       "1818377      0.020243             NaN   \n",
       "1818378      0.030070             NaN   \n",
       "1818379      0.097297             NaN   \n",
       "1818380      0.079051             NaN   \n",
       "\n",
       "                                           Query_consensus  \\\n",
       "0        MERESWAEVQLAASVEVVALSFELAVQIFAETILVEAKGCQGSTQL...   \n",
       "1        WAEVQLAASVEVVALSFELAVQIFAETILVEAKGCQGSTQLILERV...   \n",
       "2        MQSGPPPPSLFAARLVSALEHRAETAEQIAGERAKQVGELEGRVER...   \n",
       "3        FAARLVSALEHRAETAEQIAGERA-----------KQVGELEGRVE...   \n",
       "4        ESARLVADLEQRVRGAESLAAERAQQSAASKEAAAKKIAELEQRAE...   \n",
       "...                                                    ...   \n",
       "1818376     PPPPPPPPPPLPP   23 (89)pppppppppplpp   23 (89)   \n",
       "1818377           PPPPPPPLPP   23 (89)ppppppplpp   23 (89)   \n",
       "1818378  PLRQTPPPPPPPPPPLPPVKPQGVTFRHSDDTWYSENEDDLLD   ...   \n",
       "1818379  QTPPPPPPPPPPLPPVKP   26 (89)qtpppppppppplppvkp...   \n",
       "1818380  LRQTPPPPPPPPPPLPPVKP   26 (89)lrqtpppppppppplp...   \n",
       "\n",
       "                                                   Matches  \\\n",
       "0        |||++|+++||.++++|++.|||.|+|||+++|+.++|+||+++|+...   \n",
       "1        |++||||++|+|+|+++|+|+.+|||+|++++++++|+|+|++++|...   \n",
       "2        |||||||||+|++|||+.|+||.+++++|+|+|+|+||+|++|+++...   \n",
       "3        -++|||.+|++|++++++++.+|+           |+|.+|++|.+...   \n",
       "4        .++|||+.|+||.+++++|+           |.++|++++|+++++...   \n",
       "...                                                    ...   \n",
       "1818376                                      |||||||||||.|   \n",
       "1818377                                         ||||||||||   \n",
       "1818378        |-..+||+||+|+|| ||..+-..--...++.||.+---|..+   \n",
       "1818379                                 ..||||||||||.||..|   \n",
       "1818380                               +...||||||||||.||..|   \n",
       "\n",
       "                                          Target_consensus  \\\n",
       "0        mereswaevqlaasvevvalsfelavqifaetilveakgcqgstql...   \n",
       "1        ~~~L~~r~e~~v~g~~~e~a~~~Fan~l~~d~~~~~~~k~h~~l~i...   \n",
       "2        mqsgppppslfaarlvsalehraetaeqiagerakqvgelegrver...   \n",
       "3        esarlvadleqrvrgaeslaaeraqqsaaskeaaakkiaeleqrae...   \n",
       "4        faarlvsalehraetaeqia-----------gerakqvgelegrve...   \n",
       "...                                                    ...   \n",
       "1818376                           pppppppppplqp  154 (227)   \n",
       "1818377                              ppppppplpp   41 (494)   \n",
       "1818378  ~ptPtPP~~PtP~Pp-PptplP~fitQFkg~~Wf~~~fpd~~~ 10...   \n",
       "1818379                      epppppppppppqppqpp   90 (185)   \n",
       "1818380                    mpppppppppppppppppsp   20 (253)   \n",
       "\n",
       "                                           Target_sequence  \\\n",
       "0                                                      NaN   \n",
       "1        PTFLEFRVECFVSGPSIEKAFDIFANFLREDLQEINNSKDHILLGI...   \n",
       "2                                                      NaN   \n",
       "3                                                      NaN   \n",
       "4                                                      NaN   \n",
       "...                                                    ...   \n",
       "1818376                           PPPPPPPPPPLQP  154 (227)   \n",
       "1818377                              PPPPPPPLPP   41 (494)   \n",
       "1818378  PPTPTPPRPPTPPPP-PPTPLPEFITQFKGSEWFEKFFPDAQP 10...   \n",
       "1818379                      EPPPPPPPPPPPQPPQPP   90 (185)   \n",
       "1818380                                                NaN   \n",
       "\n",
       "                                                Confidence  \n",
       "0        8999999999999999999999999999999999999999999999...  \n",
       "1        8999999999999999999999999999999999999999999999...  \n",
       "2        8999999999999999999999999999999999999999999999...  \n",
       "3        468999999999999999999997           89999999999...  \n",
       "4        36899999999999999999           999999999999999...  \n",
       "...                                                    ...  \n",
       "1818376                                                NaN  \n",
       "1818377                                                NaN  \n",
       "1818378                                                NaN  \n",
       "1818379                                                NaN  \n",
       "1818380                                                NaN  \n",
       "\n",
       "[1818381 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hh_search = pd.read_csv('/home/tobiassonva/data/eukgen/processing/euk72_ep/euk72_ep.hh_self_search.tsv', sep='\\t')\n",
    "hh_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf432c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_search.Query = [n.split(' ')[0] for n in hh_search.Query]\n",
    "hh_search.Target = [n.split(' ')[0] for n in hh_search.Target]\n",
    "hh_search.replace({'pir||A44923': 'A44923', 'prf||1111187C': '1111187C'}, inplace=True)\n",
    "hh_search = hh_search.iloc[:, :2]\n",
    "#tmp.drop_duplicates(subset='Query', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd82553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop_duplicates(subset='Query', inplace=True)\n",
    "hh_search.to_csv('/home/tobiassonva/data/eukgen/processing/euk72_ep/euk72_ep.hh_self_search.tsv.unique', sep='\\t', header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9109cffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBJ25674.1</td>\n",
       "      <td>CBJ25674.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBJ25674.1</td>\n",
       "      <td>GBG24300.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBJ26231.1</td>\n",
       "      <td>CBJ26231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBJ26231.1</td>\n",
       "      <td>CBJ26231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBJ26231.1</td>\n",
       "      <td>CBJ26231.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818376</th>\n",
       "      <td>CBN80365.1</td>\n",
       "      <td>XP_005781423.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818377</th>\n",
       "      <td>CBN80365.1</td>\n",
       "      <td>XP_002295265.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818378</th>\n",
       "      <td>CBN80365.1</td>\n",
       "      <td>XP_009052733.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818379</th>\n",
       "      <td>CBN80365.1</td>\n",
       "      <td>XP_005766951.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818380</th>\n",
       "      <td>CBN80365.1</td>\n",
       "      <td>OSX74078.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1818381 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Query          Target\n",
       "0        CBJ25674.1      CBJ25674.1\n",
       "1        CBJ25674.1      GBG24300.1\n",
       "2        CBJ26231.1      CBJ26231.1\n",
       "3        CBJ26231.1      CBJ26231.1\n",
       "4        CBJ26231.1      CBJ26231.1\n",
       "...             ...             ...\n",
       "1818376  CBN80365.1  XP_005781423.1\n",
       "1818377  CBN80365.1  XP_002295265.1\n",
       "1818378  CBN80365.1  XP_009052733.1\n",
       "1818379  CBN80365.1  XP_005766951.1\n",
       "1818380  CBN80365.1      OSX74078.1\n",
       "\n",
       "[1818381 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935fbed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_acc</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBG58979.1</td>\n",
       "      <td>GBG58979.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP_509080.2</td>\n",
       "      <td>NP_509080.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XP_001311970.1</td>\n",
       "      <td>XP_001311970.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XP_002838044.1</td>\n",
       "      <td>XP_002838044.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEL96693.1</td>\n",
       "      <td>CEL96693.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191997</th>\n",
       "      <td>XP_009053570.1</td>\n",
       "      <td>XP_009053570.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191998</th>\n",
       "      <td>XP_009053570.1</td>\n",
       "      <td>OLP74334.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191999</th>\n",
       "      <td>OAE22863.1</td>\n",
       "      <td>OAE22863.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192000</th>\n",
       "      <td>XP_004346567.1</td>\n",
       "      <td>XP_004346567.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192001</th>\n",
       "      <td>PTQ45874.1</td>\n",
       "      <td>PTQ45874.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192002 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster_acc             acc\n",
       "0           GBG58979.1      GBG58979.1\n",
       "1          NP_509080.2     NP_509080.2\n",
       "2       XP_001311970.1  XP_001311970.1\n",
       "3       XP_002838044.1  XP_002838044.1\n",
       "4           CEL96693.1      CEL96693.1\n",
       "...                ...             ...\n",
       "191997  XP_009053570.1  XP_009053570.1\n",
       "191998  XP_009053570.1      OLP74334.1\n",
       "191999      OAE22863.1      OAE22863.1\n",
       "192000  XP_004346567.1  XP_004346567.1\n",
       "192001      PTQ45874.1      PTQ45874.1\n",
       "\n",
       "[192002 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_clust = pd.read_csv('/home/tobiassonva/data/eukgen/processing/euk72_ep/euk72_ep.test_clust.tsv', sep='\\t', header=None, names=['cluster_acc', 'acc'])\n",
    "\n",
    "casc_clust =  pd.read_csv('/home/tobiassonva/data/eukgen/processing/euk72_ep/euk72_ep.repseq.cascaded_cluster.tsv', sep='\\t', header=None, names=['cluster_acc', 'acc'])\n",
    "\n",
    "hh_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d74baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "casc_clusters = casc_clust.set_index('acc').loc[hh_clust.acc].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9c30d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GBG58979.1', 'NP_509080.2', 'XP_001311970.1', 'XP_002838044.1',\n",
       "       'CEL96693.1', 'EP00615P012161', 'EP00615P004769', 'EP00615P003329',\n",
       "       'EP00615P017473', 'EP00615P007201',\n",
       "       ...\n",
       "       'XP_008897273.1', 'XP_020406395.1', 'XP_001745180.1', 'NP_012105.1',\n",
       "       'GBG59653.1', 'XP_009053570.1', 'OLP74334.1', 'OAE22863.1',\n",
       "       'XP_004346567.1', 'PTQ45874.1'],\n",
       "      dtype='object', name='acc', length=192002)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casc_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b15b7523",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['GBG58979.1', 'NP_509080.2', 'XP_001311970.1', 'XP_002838044.1',\\n       'CEL96693.1', 'EP00615P012161', 'EP00615P004769', 'EP00615P003329',\\n       'EP00615P017473', 'EP00615P007201',\\n       ...\\n       'XP_008897273.1', 'XP_020406395.1', 'XP_001745180.1', 'NP_012105.1',\\n       'GBG59653.1', 'XP_009053570.1', 'OLP74334.1', 'OAE22863.1',\\n       'XP_004346567.1', 'PTQ45874.1'],\\n      dtype='object', length=192002)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcasc_clust\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcasc_clusters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['GBG58979.1', 'NP_509080.2', 'XP_001311970.1', 'XP_002838044.1',\\n       'CEL96693.1', 'EP00615P012161', 'EP00615P004769', 'EP00615P003329',\\n       'EP00615P017473', 'EP00615P007201',\\n       ...\\n       'XP_008897273.1', 'XP_020406395.1', 'XP_001745180.1', 'NP_012105.1',\\n       'GBG59653.1', 'XP_009053570.1', 'OLP74334.1', 'OAE22863.1',\\n       'XP_004346567.1', 'PTQ45874.1'],\\n      dtype='object', length=192002)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "casc_clust.loc[casc_clusters.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6832e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/tobiassonva/data/eukgen/processing/euk72_ep/'\n",
    "with open(root+'euk72_ep.test_clust', 'r') as infile:\n",
    "    clusters = [line for line in infile.read().split('\\n')]\n",
    "    \n",
    "cluster_seqs_lookup = pd.read_csv(root+'euk72_ep.test_seqs.lookup', sep='\\t', header=None, names = ['a', 'b', 'c'])\n",
    "repseq_seqs_lookup = pd.read_csv(root+'euk72_ep.repseq.lookup', sep='\\t', header=None, names = ['a', 'b', 'c'])\n",
    "\n",
    "cluster_seqs_lookup.set_index('a', inplace=True)\n",
    "repseq_seqs_lookup_reverse = repseq_seqs_lookup.set_index('a')\n",
    "repseq_seqs_lookup.set_index('b', inplace=True)\n",
    "\n",
    "cluster_seqs_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "repseq_seqs_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repseq_seqs_lookup_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "idlines = [int(line.strip('\\x00')) for line in clusters if line.strip('\\x00') != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_seqs_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40997639",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cluster_seqs_lookup.loc[idlines].b\n",
    "repseq_accs = repseq_seqs_lookup.loc[cluster_seqs_lookup.loc[idlines].b]\n",
    "repseq_ids = repseq_accs[~repseq_accs.index.duplicated(keep='first')].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ffd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [False if i[0] == \"\\x00\" else True for i in clusters]\n",
    "with open(root+'euk72_ep.test_clust_edit', 'w') as out:\n",
    "    for i, n in enumerate(repseq_ids):\n",
    "        print(i,n)\n",
    "        if indexes[i]:\n",
    "            out.write(str(n)+'\\n')\n",
    "        else:\n",
    "            out.write('\\x00'+str(n)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645894b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(repseq_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59030eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d147c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
