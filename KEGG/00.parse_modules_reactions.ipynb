{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e71991-2581-409c-9ef7-ad58afc3cf38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from collections import defaultdict \n",
    "import ast\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9da1f48-3c02-442f-9508-eaeb6b48d764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rowdict(infile):\n",
    "    entry_row, symbol_row, name_row, pathway_row = False, False, False, False\n",
    "    module_row, reaction_row, network_row, disease_row, brite_row, dblinks_row, gene_row, ref_row = False, False, False, False, False, False, False, False\n",
    "    with open(infile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for row_ind in range(0, len(lines)):\n",
    "            line = lines[row_ind]\n",
    "            line = line.split(\"  \")\n",
    "            if line[0] == \"ENTRY\":\n",
    "                entry_row = row_ind\n",
    "            elif line[0] == \"SYMBOL\":\n",
    "                symbol_row = row_ind\n",
    "            elif line[0] == \"NAME\":\n",
    "                name_row = row_ind\n",
    "            elif line[0] == \"PATHWAY\":\n",
    "                pathway_row = row_ind\n",
    "            elif line[0] == \"MODULE\":\n",
    "                module_row = row_ind\n",
    "            elif line[0] == \"REACTION\":\n",
    "                reaction_row = row_ind\n",
    "            elif line[0] == \"NETWORK\":\n",
    "                network_row = row_ind\n",
    "            elif line[0] == \"DISEASE\":\n",
    "                disease_row = row_ind\n",
    "            elif line[0] == \"BRITE\":\n",
    "                brite_row = row_ind\n",
    "            elif line[0] == \"DBLINKS\":\n",
    "                dblinks_row = row_ind\n",
    "            elif line[0] == \"GENES\":\n",
    "                gene_row = row_ind\n",
    "            elif line[0] == \"REFERENCE\":\n",
    "                ref_row = row_ind\n",
    "                break\n",
    "        rows_dict = {\"pathway\": pathway_row, \"module\": module_row, \"reaction\": reaction_row, \"network\": network_row,\n",
    "             \"disease\": disease_row, \"brite\": brite_row, \"dblinks\": dblinks_row, \"gene\": gene_row, \"ref\": ref_row}\n",
    "        return rows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b0a9fc-4dd1-4c2b-86e9-e475cf5e2a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_module_id(lines, row_dict, out_dict): # if it exists, 3:4\n",
    "    key1, key2 = \"MODULE_ID\", \"MODULE_NAME\"\n",
    "    if not row_dict[\"module\"]:\n",
    "        out_dict[key1].append(nan)\n",
    "        out_dict[key2].append(nan)\n",
    "    else:\n",
    "        module_row = row_dict[\"module\"]\n",
    "        ordered_keys = [\"reaction\", \"network\", \"disease\", \"brite\", \"dblinks\", \"gene\", \"ref\"]\n",
    "        ind = 0\n",
    "        next_section_row = row_dict[ordered_keys[ind]]\n",
    "        try:\n",
    "            while not next_section_row:\n",
    "                ind = ind + 1\n",
    "                next_section_row = row_dict[ordered_keys[ind]]\n",
    "        except: # module is the last key\n",
    "            next_section_row = len(lines) - 1 # iterates up to the second to last line\n",
    "        lines[module_row] = lines[module_row][6:] # remove \"module_row\" header\n",
    "        ids, names = [], []\n",
    "        for line in lines[module_row:next_section_row]:\n",
    "            try:\n",
    "                module_id, name = line.strip().split(\"  \")\n",
    "                ids.append(module_id)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                continue\n",
    "        # get two columns, split into multiple rows later\n",
    "        out_dict[key1].append(\"DELIMITER?XD\".join(ids))\n",
    "        out_dict[key2].append(\"DELIMITER?XD\".join(names))\n",
    "        \n",
    "def parse_reaction_id(lines, row_dict, out_dict): # if it exists, 3:4\n",
    "    key1, key2 = \"REACTION_ID\", \"REACTION_NAME\"\n",
    "    if not row_dict[\"reaction\"]:\n",
    "        out_dict[key1].append(nan)\n",
    "        out_dict[key2].append(nan)\n",
    "    else:\n",
    "        reaction_row = row_dict[\"reaction\"]\n",
    "        ordered_keys = [\"network\", \"disease\", \"brite\", \"dblinks\", \"gene\", \"ref\"]\n",
    "        ind = 0\n",
    "        next_section_row = row_dict[ordered_keys[ind]]\n",
    "        try:\n",
    "            while not next_section_row:\n",
    "                ind = ind + 1\n",
    "                next_section_row = row_dict[ordered_keys[ind]]\n",
    "        except: # reaction is the last key\n",
    "            next_section_row = len(lines) - 1 # iterates up to the second to last line\n",
    "        lines[reaction_row] = lines[reaction_row][8:] # remove \"reaction_row\" header\n",
    "        ids, names = [], []\n",
    "        for line in lines[reaction_row:next_section_row]:\n",
    "            try:\n",
    "                reaction_id, name = line.strip().split(\"  \")\n",
    "                ids.append(reaction_id)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                continue\n",
    "        # get two columns, split into multiple rows later\n",
    "        out_dict[key1].append(\"DELIMITER?XD\".join(ids))\n",
    "        out_dict[key2].append(\"DELIMITER?XD\".join(names))\n",
    "        \n",
    "def parse_name(name_row, lines, out_dict): # standard rows- 2:3\n",
    "    key = \"NAME\"\n",
    "    name_ec = lines[name_row][len(key):].strip().split(\" [\") #\n",
    "    name = name_ec[0]\n",
    "    out_dict[key].append(name)\n",
    "    \n",
    "def parse_entry(entry_row, lines, out_dict): # standard rows- 0:1\n",
    "    key = \"ENTRY\"\n",
    "    line_list = lines[entry_row][len(key):].strip().split(\" \")\n",
    "    entry = line_list[0]\n",
    "    out_dict[key].append(entry)\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2c6dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_values(start_row, end_row, lines, out_dict):\n",
    "    key = lines[start_row].split(\" \")[0]\n",
    "    lines[start_row] = lines[start_row][len(key):]\n",
    "    entry = []\n",
    "    for line in lines[start_row:end_row]:\n",
    "        line = line.strip().split(\"  \")\n",
    "        line = [str for str in line if len(str) > 0]\n",
    "        entry += line\n",
    "    out_dict[key].append(entry)\n",
    "    \n",
    "def parse_values2dict(start_row, end_row, lines, out_dict):\n",
    "    if not start_row:\n",
    "        return\n",
    "    elif not end_row:\n",
    "        key = lines[start_row].split(\" \")[0]\n",
    "    lines[start_row] = lines[start_row][len(key):]\n",
    "    value_dict = {}\n",
    "    for line in lines[start_row:end_row]:\n",
    "        line = line.strip().split(\"  \")\n",
    "        line = [str for str in line if len(str) > 0]\n",
    "        key2, val2 = line[0], line[1]\n",
    "        value_dict[key2] = val2\n",
    "    out_dict[key].append(value_dict)\n",
    "    \n",
    "def remove_innermost_brackets(dict_str):\n",
    "    return re.sub(r\"\\{([^{}]+)\\}\", r\"\\1\", dict_str)\n",
    "\n",
    "def parse_json(row_dict, lines, out_dict): # construct a json string and convert to dictionary\n",
    "    key = \"BRITE\"\n",
    "    if not row_dict[\"brite\"]:\n",
    "        out_dict[key].append(nan)\n",
    "    else:\n",
    "        start_row = row_dict[\"brite\"]\n",
    "        ordered_keys = [\"dblinks\", \"gene\", \"ref\"]\n",
    "        ind = 0\n",
    "        end_row = row_dict[ordered_keys[ind]]\n",
    "        try:\n",
    "            while not end_row:\n",
    "                ind = ind + 1\n",
    "                end_row = row_dict[ordered_keys[ind]]\n",
    "        except: # brite is the last key\n",
    "            end_row = len(lines) - 1 # iterates up to the second to last line\n",
    "            \n",
    "        #key = lines[start_row].split(\" \")[0]\n",
    "        lines[start_row] = lines[start_row][len(key):]\n",
    "\n",
    "        base_headsize = len(lines[start_row]) - len(lines[start_row].lstrip()) + len(key) # get the number of characters preceding first json entry\n",
    "        prev_level = 0\n",
    "        dict_str = '{\"' + lines[start_row].strip() + '\"'\n",
    "        for line in lines[start_row + 1:end_row]:\n",
    "            cur_headsize = len(line) - len(line.lstrip())\n",
    "            level = cur_headsize - base_headsize # level 0 would be base, level 1 would be 1 indent, so on .. levels always change for the BRITEfield\n",
    "            #print(level)\n",
    "            line = line.strip().replace(\"\\\"\", \"~double~\").replace(\"\\'\", \"~single~\") # fix parsing bug\n",
    "            if level > prev_level:\n",
    "                dict_str += ': {\"' + line + '\"'\n",
    "            else:\n",
    "                ascents = prev_level - level\n",
    "                dict_str += '}'*ascents + ', \"' + line + '\"'\n",
    "            prev_level = level\n",
    "        dict_str += '}'*(level + 1)\n",
    "        dict_str_clean = remove_innermost_brackets(dict_str)\n",
    "        entry = ast.literal_eval(dict_str)\n",
    "        out_dict[key].append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c327d76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KEGG Orthology (KO) [BR:ko00001]': {'09180 Brite Hierarchies': {'09183 Protein families: signaling and cellular processes': {'01504 Antimicrobial resistance genes': {'K00984  aadA; streptomycin doubleprime-adenylyltransferase'}}}},\n",
       " 'Enzymes [BR:ko01000]': {'2. Transferases': {'2.7  Transferring phosphorus-containing groups': {'2.7.7  Nucleotidyltransferases': {\"2.7.7.47  streptomycin 3prime'-adenylyltransferase\": {'K00984  aadA; streptomycin doubleprime-adenylyltransferase'}}}}},\n",
       " 'Antimicrobial resistance genes [BR:ko01504]': {'Gene variants': {'Aminoglycoside resistance genes': {'O-Nucleotidyltransferases': {'K00984  aadA; streptomycin doubleprime-adenylyltransferase'}}}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_str_test = \"\"\"\n",
    "{\"KEGG Orthology (KO) [BR:ko00001]\": {\"09180 Brite Hierarchies\": {\"09183 Protein families: signaling and cellular processes\": {\"01504 Antimicrobial resistance genes\": {\"K00984  aadA; streptomycin 3\"-adenylyltransferase\"}}}}, \"Enzymes [BR:ko01000]\": {\"2. Transferases\": {\"2.7  Transferring phosphorus-containing groups\": {\"2.7.7  Nucleotidyltransferases\": {\"2.7.7.47  streptomycin 3''-adenylyltransferase\": {\"K00984  aadA; streptomycin 3\"-adenylyltransferase\"}}}}}, \"Antimicrobial resistance genes [BR:ko01504]\": {\"Gene variants\": {\"Aminoglycoside resistance genes\": {\"O-Nucleotidyltransferases\": {\"K00984  aadA; streptomycin 3\"-adenylyltransferase\"}}}}}\n",
    "\"\"\".replace(\"3\\\"\", \"doubleprime\").replace(\"3'\", \"3prime\")\n",
    "ast.literal_eval(dict_str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "462e4de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26440"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_out_dict[\"BRITE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a9e48239-6f63-43f5-8fa0-f62880fe401d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#K26474 requires encoding = latin-1, not default utf-8)\n",
    "\n",
    "infiles = [\"/data/luojaa/KO/\" + file for file in os.listdir(\"/data/luojaa/KO/\")]\n",
    "infiles.remove(\"/data/luojaa/KO/K26474.txt\")\n",
    "infiles_1000 = infiles[:1000]\n",
    "\n",
    "# construct full sized dataframe dictionary\n",
    "full_out_dict = defaultdict(list)\n",
    "for infile in infiles:\n",
    "    with open(infile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        row_dict = get_rowdict(infile)\n",
    "        entry = parse_entry(0, lines, full_out_dict)\n",
    "#         parse_name(2, lines, full_out_dict)\n",
    "#         parse_module_id(lines, row_dict, full_out_dict)\n",
    "#         parse_reaction_id(lines, row_dict, full_out_dict)\n",
    "        parse_json(row_dict, lines, full_out_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0dc0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out_dict[\"ENTRY\"] = full_out_dict2[\"ENTRY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2dc3c050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type({}) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e333e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsondict2list(jdict):\n",
    "    rv = []\n",
    "    if type(jdict) != dict:\n",
    "        return []\n",
    "    for key in list(jdict.keys()):\n",
    "        rv += [key]\n",
    "        rv += jsondict2list(jdict[key])\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dcd61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jd2l_wrapper(jdict):\n",
    "    d = jdict[\"KEGG Orthology (KO) [BR:ko00001]\"]\n",
    "    rv = jsondict2list(d)\n",
    "    rv = list(set(rv))\n",
    "    rv = [i.replace(\"~double~\", \"\\\"\").replace(\"~single~\", \"\\'\") for i in rv]\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7c3d97e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['09100 Metabolism',\n",
       " '09101 Carbohydrate metabolism',\n",
       " '00010 Glycolysis / Gluconeogenesis',\n",
       " '00620 Pyruvate metabolism',\n",
       " '09103 Lipid metabolism',\n",
       " '00071 Fatty acid degradation',\n",
       " '09105 Amino acid metabolism',\n",
       " '00350 Tyrosine metabolism',\n",
       " '09108 Metabolism of cofactors and vitamins',\n",
       " '00830 Retinol metabolism',\n",
       " '09111 Xenobiotics biodegradation and metabolism',\n",
       " '00625 Chloroalkane and chloroalkene degradation',\n",
       " '00626 Naphthalene degradation',\n",
       " '00980 Metabolism of xenobiotics by cytochrome P450',\n",
       " '00982 Drug metabolism - cytochrome P450']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = full_out_dict[\"BRITE\"][0][\"KEGG Orthology (KO) [BR:ko00001]\"]\n",
    "jsondict2list(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8f6c333d-c2fe-4464-9722-3b0f4f1bfc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary_full = pd.DataFrame(full_out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "34ac9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_full[\"list\"] = df_summary_full.BRITE.apply(jd2l_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e7c3b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brite_id(lst):\n",
    "    rv = []\n",
    "    for i in lst:\n",
    "        rv.append(i.split(\" \")[0])\n",
    "    return rv\n",
    "def extract_brite_desc(lst):\n",
    "    rv = []\n",
    "    for i in lst:\n",
    "        split = i.split(\" \")\n",
    "        desc = \" \".join(split[1:])\n",
    "        rv.append(desc)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0e30f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_full[\"brite_ids\"] = df_summary_full.list.apply(extract_brite_id)\n",
    "df_summary_full[\"brite_descriptions\"] = df_summary_full.list.apply(extract_brite_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e0d7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kog2briteids = df_summary_full.loc[:,[\"ENTRY\"]]\n",
    "kog2briteids[\"brite_ids\"] = df_summary_full.brite_ids.apply(lambda x: \"|\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2998bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kog2briteids.to_csv(\"/data/luojaa/kegg_stats/kog2briteids.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef19033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brite_mappings = df_summary_full.explode([\"brite_ids\", \"brite_descriptions\"]).loc[:,[\"brite_ids\",\"brite_descriptions\"]].drop_duplicates().sort_values(\"brite_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e7fa6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brite_mappings.to_csv(\"/data/luojaa/kegg_stats/kog_brite_mappings.tsv\", sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1491c77b-80a9-420e-9e08-12d0e64c5e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_summary_full = pd.DataFrame(full_out_dict)\n",
    "# df_summary_full[\"REACTION_ID\"] = df_summary_full[\"REACTION_ID\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "# df_summary_full[\"REACTION_NAME\"] = df_summary_full[\"REACTION_NAME\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "# df_summary_full[\"MODULE_ID\"] = df_summary_full[\"MODULE_ID\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "# df_summary_full[\"MODULE_NAME\"] = df_summary_full[\"MODULE_NAME\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baa97e4b-73cf-428a-89b7-ba48b5792949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_summary_rxn = df_summary_full.explode([\"REACTION_ID\", \"REACTION_NAME\"]).loc[:,[\"ENTRY\", \"REACTION_ID\", \"REACTION_NAME\"]]\n",
    "# df_summary_module = df_summary_full.explode([\"MODULE_ID\", \"MODULE_NAME\"]).loc[:,[\"ENTRY\", \"MODULE_ID\", \"MODULE_NAME\"]]\n",
    "# df_summary_rxn.to_csv('/data/luojaa/kegg/kegg_reactions.tsv', sep = \"\\t\", index = False)  \n",
    "# df_summary_module.to_csv('/data/luojaa/kegg/kegg_modules.tsv', sep = \"\\t\", index = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1a003-dccb-436e-9f0c-1de8b8b094a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
