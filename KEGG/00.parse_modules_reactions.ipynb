{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e71991-2581-409c-9ef7-ad58afc3cf38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from collections import defaultdict \n",
    "import ast\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9da1f48-3c02-442f-9508-eaeb6b48d764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rowdict(infile):\n",
    "    entry_row, symbol_row, name_row, pathway_row = False, False, False, False\n",
    "    module_row, reaction_row, network_row, disease_row, brite_row, dblinks_row, gene_row, ref_row = False, False, False, False, False, False, False, False\n",
    "    with open(infile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for row_ind in range(0, len(lines)):\n",
    "            line = lines[row_ind]\n",
    "            line = line.split(\"  \")\n",
    "            if line[0] == \"ENTRY\":\n",
    "                entry_row = row_ind\n",
    "            elif line[0] == \"SYMBOL\":\n",
    "                symbol_row = row_ind\n",
    "            elif line[0] == \"NAME\":\n",
    "                name_row = row_ind\n",
    "            elif line[0] == \"PATHWAY\":\n",
    "                pathway_row = row_ind\n",
    "            elif line[0] == \"MODULE\":\n",
    "                module_row = row_ind\n",
    "            elif line[0] == \"REACTION\":\n",
    "                reaction_row = row_ind\n",
    "            elif line[0] == \"NETWORK\":\n",
    "                network_row = row_ind\n",
    "            elif line[0] == \"DISEASE\":\n",
    "                disease_row = row_ind\n",
    "            elif line[0] == \"BRITE\":\n",
    "                brite_row = row_ind\n",
    "            elif line[0] == \"DBLINKS\":\n",
    "                dblinks_row = row_ind\n",
    "            elif line[0] == \"GENES\":\n",
    "                gene_row = row_ind\n",
    "            elif line[0] == \"REFERENCE\":\n",
    "                ref_row = row_ind\n",
    "                break\n",
    "        rows_dict = {\"pathway\": pathway_row, \"module\": module_row, \"reaction\": reaction_row, \"network\": network_row,\n",
    "             \"disease\": disease_row, \"brite\": brite_row, \"dblinks\": dblinks_row, \"gene\": gene_row, \"ref\": ref_row}\n",
    "        return rows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57b0a9fc-4dd1-4c2b-86e9-e475cf5e2a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_module_id(lines, row_dict, out_dict): # if it exists, 3:4\n",
    "    key1, key2 = \"MODULE_ID\", \"MODULE_NAME\"\n",
    "    if not row_dict[\"module\"]:\n",
    "        out_dict[key1].append(nan)\n",
    "        out_dict[key2].append(nan)\n",
    "    else:\n",
    "        module_row = row_dict[\"module\"]\n",
    "        ordered_keys = [\"reaction\", \"network\", \"disease\", \"brite\", \"dblinks\", \"gene\", \"ref\"]\n",
    "        ind = 0\n",
    "        next_section_row = row_dict[ordered_keys[ind]]\n",
    "        try:\n",
    "            while not next_section_row:\n",
    "                ind = ind + 1\n",
    "                next_section_row = row_dict[ordered_keys[ind]]\n",
    "        except: # module is the last key\n",
    "            next_section_row = len(lines) - 1 # iterates up to the second to last line\n",
    "        lines[module_row] = lines[module_row][6:] # remove \"module_row\" header\n",
    "        ids, names = [], []\n",
    "        for line in lines[module_row:next_section_row]:\n",
    "            try:\n",
    "                module_id, name = line.strip().split(\"  \")\n",
    "                ids.append(module_id)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                continue\n",
    "        # get two columns, split into multiple rows later\n",
    "        out_dict[key1].append(\"DELIMITER?XD\".join(ids))\n",
    "        out_dict[key2].append(\"DELIMITER?XD\".join(names))\n",
    "        \n",
    "def parse_reaction_id(lines, row_dict, out_dict): # if it exists, 3:4\n",
    "    key1, key2 = \"REACTION_ID\", \"REACTION_NAME\"\n",
    "    if not row_dict[\"reaction\"]:\n",
    "        out_dict[key1].append(nan)\n",
    "        out_dict[key2].append(nan)\n",
    "    else:\n",
    "        reaction_row = row_dict[\"reaction\"]\n",
    "        ordered_keys = [\"network\", \"disease\", \"brite\", \"dblinks\", \"gene\", \"ref\"]\n",
    "        ind = 0\n",
    "        next_section_row = row_dict[ordered_keys[ind]]\n",
    "        try:\n",
    "            while not next_section_row:\n",
    "                ind = ind + 1\n",
    "                next_section_row = row_dict[ordered_keys[ind]]\n",
    "        except: # reaction is the last key\n",
    "            next_section_row = len(lines) - 1 # iterates up to the second to last line\n",
    "        lines[reaction_row] = lines[reaction_row][8:] # remove \"reaction_row\" header\n",
    "        ids, names = [], []\n",
    "        for line in lines[reaction_row:next_section_row]:\n",
    "            try:\n",
    "                reaction_id, name = line.strip().split(\"  \")\n",
    "                ids.append(reaction_id)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                continue\n",
    "        # get two columns, split into multiple rows later\n",
    "        out_dict[key1].append(\"DELIMITER?XD\".join(ids))\n",
    "        out_dict[key2].append(\"DELIMITER?XD\".join(names))\n",
    "        \n",
    "def parse_name(name_row, lines, out_dict): # standard rows- 2:3\n",
    "    key = \"NAME\"\n",
    "    name_ec = lines[name_row][len(key):].strip().split(\" [\") #\n",
    "    name = name_ec[0]\n",
    "    out_dict[key].append(name)\n",
    "    \n",
    "def parse_entry(entry_row, lines, out_dict): # standard rows- 0:1\n",
    "    key = \"ENTRY\"\n",
    "    line_list = lines[entry_row][len(key):].strip().split(\" \")\n",
    "    entry = line_list[0]\n",
    "    out_dict[key].append(entry)\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9e48239-6f63-43f5-8fa0-f62880fe401d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#K26474 requires encoding = latin-1, not default utf-8)\n",
    "\n",
    "#infiles = [\"/data/luojaa/KO/\" + file for file in os.listdir(\"/data/luojaa/KO/\")]\n",
    "#infiles.remove(\"/data/luojaa/KO/K26474.txt\")\n",
    "infiles_1000 = infiles[:1000]\n",
    "\n",
    "# construct full sized dataframe dictionary\n",
    "full_out_dict = defaultdict(list)\n",
    "for infile in infiles:\n",
    "    with open(infile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        row_dict = get_rowdict(infile)\n",
    "        entry = parse_entry(0, lines, full_out_dict)\n",
    "        parse_name(2, lines, full_out_dict)\n",
    "        parse_module_id(lines, row_dict, full_out_dict)\n",
    "        parse_reaction_id(lines, row_dict, full_out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f6c333d-c2fe-4464-9722-3b0f4f1bfc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary_full = pd.DataFrame(full_out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1491c77b-80a9-420e-9e08-12d0e64c5e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary_full = pd.DataFrame(full_out_dict)\n",
    "df_summary_full[\"REACTION_ID\"] = df_summary_full[\"REACTION_ID\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "df_summary_full[\"REACTION_NAME\"] = df_summary_full[\"REACTION_NAME\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "df_summary_full[\"MODULE_ID\"] = df_summary_full[\"MODULE_ID\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "df_summary_full[\"MODULE_NAME\"] = df_summary_full[\"MODULE_NAME\"].apply(lambda pathway: pathway.split(\"DELIMITER?XD\") if not pd.isnull(pathway) else nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baa97e4b-73cf-428a-89b7-ba48b5792949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_rxn = df_summary_full.explode([\"REACTION_ID\", \"REACTION_NAME\"]).loc[:,[\"ENTRY\", \"REACTION_ID\", \"REACTION_NAME\"]]\n",
    "df_summary_module = df_summary_full.explode([\"MODULE_ID\", \"MODULE_NAME\"]).loc[:,[\"ENTRY\", \"MODULE_ID\", \"MODULE_NAME\"]]\n",
    "df_summary_rxn.to_csv('/data/luojaa/kegg/kegg_reactions.tsv', sep = \"\\t\", index = False)  \n",
    "df_summary_module.to_csv('/data/luojaa/kegg/kegg_modules.tsv', sep = \"\\t\", index = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1a003-dccb-436e-9f0c-1de8b8b094a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
